# Quenderin

**Local LLM-powered code generation toolchain** - Generate production-ready code from natural language prompts.

## âš¡ Super Quick Start (2 minutes)

```bash
# 1. Install dependencies
npm install && npm run build

# 2. Run setup wizard
node dist/index.js setup

# 3. Generate code!
node dist/index.js add "Create a function to validate email addresses"
```

The setup wizard will:
- âœ¨ Auto-detect Ollama if installed (easiest option)
- ðŸŽ¯ Guide you through OpenAI API setup (1 minute)
- ðŸ”Œ Support any OpenAI-compatible API (OpenRouter, LocalAI, etc.)
- ðŸ“¦ No model downloads required for cloud/Ollama options

**See [SIMPLE-SETUP.md](SIMPLE-SETUP.md) for detailed options.**

---

## What is Quenderin?

Quenderin is **not** a framework, a platform, or a magic black box. It is a **compiler-level toolchain** that:

1.  Reads your existing schema (Prisma, Drizzle, SQL, or plain TypeScript).
2.  Consumes natural-language prompts stored as version-controlled markdown.
3.  Generates plain source files into a `.gitignore`-safe `src/gen/` directory.
4.  Supports **multiple LLM backends**: Ollama (local), OpenAI, or offline GGUF models.

You are trading the time it takes to write tedious boilerplate for the time it takes to review a well-structured pull request.

---
## LLM Provider Options

| Provider | Setup Time | Cost | Best For |
|----------|-----------|------|----------|
| **Ollama** | 2 min | Free | Local development, no API keys |
| **OpenAI** | 1 min | Pay per use | Production, best quality |
| **OpenAI-compatible** | 1 min | Varies | OpenRouter, LocalAI, LM Studio |
| **GGUF Models** | 15+ min | Free | Completely offline, full control |

## The Workflow

```bash
# Initialize your project
node dist/index.js init

# Quick setup to connect LLM
node dist/index.js setup

# Generate code from natural language
node dist/index.js add "Stripe checkout with Apple Pay, EU VAT, and SCA"

# Save directly to file
node dist/index.js add "Create auth middleware" -o src/gen/auth.ts
```

The tool generates clean, production-ready code with comments and proper error handling.

-----

## Core Guarantees & Trade-offs

This tool is built to answer the hard questions of code generation.

| Promise | The Reality (How It Works) |
|---|---|
| **Deterministic Output** | The default LLM is a bundled 7B GGUF model, pinned to a specific SHA hash. Same schema + same prompt â†’ identical output, forever. No drift. |
| **Manageable Reviews** | PRs are automatically split into small, logical commits, with a hard limit of \~300 lines per PR. No 3,000-line monoliths. |
| **Safe Manual Edits** | The "ejection problem" is solved via `quenderin freeze src/gen/checkout.ts`. This moves the file to `src/handwritten/`, rewrites all imports, and tells the generator to never touch it again. You are always in control. |
| **No Context Explosion** | The CLI fails if local context exceeds a safe token budget. You guide context discovery with explicit `--include` and `--exclude` globs in your config. |
| **No Hidden Runtime** | Zero network calls after initial installation. Zero telemetry unless you explicitly opt-in. It runs on your machine, period. |

-----

## Visible Dependency Graph

Each generated file is annotated with its dependencies. You can visualize the impact of a change before you make it.

```typescript
// src/gen/checkout/resolver.ts
// Generated by prompt: stripe-checkout.md
// Depends on: schema.User, src/lib/auth.ts
// Consumers: src/pages/api/checkout.ts
```

Run `quenderin deps <file>` to output a Mermaid diagram of its local dependencies.

-----

## Economics

The default, offline model means the cost is fixed.

| Scenario | Generated Tokens / month | Cloud API Cost |
|---|---|---|
| Any project size | Unlimited | **$0** |

You can optionally configure your own API key for a larger cloud model, but it is not required.

-----

## License & Ownership

MIT.
